{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4mDg5eUyDJh"
      },
      "source": [
        "# 2. OpenAI の チャット API の基礎\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCaw75pIyDJi"
      },
      "source": [
        "## 2.3. 入出力の長さの制限や料金に影響する「トークン」\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBsFB8GsyDJi"
      },
      "source": [
        "### トークン\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "61dKKBaTyDJi",
        "outputId": "eabe4825-b0a8-4460-bd50-02bf6fdd6f3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken==0.7.0\n",
            "  Downloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken==0.7.0) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken==0.7.0) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken==0.7.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken==0.7.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken==0.7.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken==0.7.0) (2025.1.31)\n",
            "Downloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tiktoken==0.7.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dnGrVgAqyDJj",
        "outputId": "827da96f-e90a-4411-f396-5b1e24f404b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chat\n",
            "GPT\n"
          ]
        }
      ],
      "source": [
        "import tiktoken\n",
        "\n",
        "text = \"ChatGPT\"\n",
        "\n",
        "encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
        "tokens = encoding.encode(text)\n",
        "for token in tokens:\n",
        "    print(encoding.decode([token]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dk45xJw2yDJj"
      },
      "source": [
        "### Tokenizer と tiktoken の紹介\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1HN_Myl_yDJj",
        "outputId": "4cf1d644-87bf-4d9e-8f90-280e43cda2d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "37\n"
          ]
        }
      ],
      "source": [
        "import tiktoken\n",
        "\n",
        "text = \"LLMを使ってクールなものを作るのは簡単だが、プロダクションで使えるものを作るのは非常に難しい。\"\n",
        "\n",
        "encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
        "tokens = encoding.encode(text)\n",
        "print(len(tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03vTuk40yDJj"
      },
      "source": [
        "## 2.4. Chat Completions API を試す環境の準備\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojlIE6ThyDJj"
      },
      "source": [
        "### OpenAI の API キーの準備\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aUW0Z0HZyDJj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttewC-d5yDJj"
      },
      "source": [
        "## 2.5. Chat Completions API のハンズオン\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqI85_XiyDJj"
      },
      "source": [
        "### OpenAI のライブラリ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFGSyZN8yDJj"
      },
      "source": [
        "#### 【注意】既知のエラーについて\n",
        "\n",
        "openai パッケージが依存する httpx のアップデートにより、`openai==1.40.6` を使用する箇所で `TypeError: Client.__init__() got an unexpected keyword argument 'proxies'` というエラーが発生するようになりました。\n",
        "\n",
        "このエラーは、`!pip install httpx==0.27.2` のように、httpx の特定バージョンをインストールすることで回避することができます。\n",
        "\n",
        "なお、Google Colab で一度上記のエラーに遭遇したあとで `!pip install httpx==0.27.2` のようにパッケージをインストールし直した場合、以下のどちらかの操作を実施する必要があります。\n",
        "\n",
        "- Google Colab の「ランタイム」から「セッションを再起動する」を実行する\n",
        "- 「ランタイムを接続解除して削除」を実行してパッケージのインストールからやり直す\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MkvRFcWeyDJj",
        "outputId": "e05fb7be-aa12-49a9-d10f-0e99401594f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai==1.40.6 in /usr/local/lib/python3.11/dist-packages (1.40.6)\n",
            "Requirement already satisfied: httpx==0.27.2 in /usr/local/lib/python3.11/dist-packages (0.27.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.40.6) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.40.6) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.40.6) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.40.6) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai==1.40.6) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai==1.40.6) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai==1.40.6) (4.12.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx==0.27.2) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx==0.27.2) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx==0.27.2) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx==0.27.2) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai==1.40.6) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai==1.40.6) (2.27.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai==1.40.6 httpx==0.27.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIG0HTHhyDJj"
      },
      "source": [
        "### Chat Completions API の呼び出し\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hO1yewZVyDJj",
        "outputId": "f5f0fa32-4d0a-4d62-b60b-f60a4a9e7211",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-B9n0LH2KcjoySQkfxVzCHSEPriyNN\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"message\": {\n",
            "        \"content\": \"こんにちは、ジョンさん！お会いできてうれしいです。今日はどんなことをお話ししたいですか？\",\n",
            "        \"refusal\": null,\n",
            "        \"role\": \"assistant\"\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1741673025,\n",
            "  \"model\": \"gpt-4o-mini-2024-07-18\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"service_tier\": \"default\",\n",
            "  \"system_fingerprint\": \"fp_06737a9306\",\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 30,\n",
            "    \"prompt_tokens\": 25,\n",
            "    \"total_tokens\": 55,\n",
            "    \"prompt_tokens_details\": {\n",
            "      \"cached_tokens\": 0,\n",
            "      \"audio_tokens\": 0\n",
            "    },\n",
            "    \"completion_tokens_details\": {\n",
            "      \"reasoning_tokens\": 0,\n",
            "      \"audio_tokens\": 0,\n",
            "      \"accepted_prediction_tokens\": 0,\n",
            "      \"rejected_prediction_tokens\": 0\n",
            "    }\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"こんにちは！私はジョンと言います！\"},\n",
        "    ],\n",
        ")\n",
        "print(response.to_json(indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWk3Mui5yDJj"
      },
      "source": [
        "### 会話履歴を踏まえた応答を得る\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "W2jOSzUfyDJj",
        "outputId": "82280c68-da7d-4eb3-b8b9-3cd864f225ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-B9n0dSdhLCqWH2IX1Ki7o3Ysid8ap\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"message\": {\n",
            "        \"content\": \"はい、あなたの名前はジョンさんです！他に何かお手伝いできることがあれば教えてください。\",\n",
            "        \"refusal\": null,\n",
            "        \"role\": \"assistant\"\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1741673043,\n",
            "  \"model\": \"gpt-4o-mini-2024-07-18\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"service_tier\": \"default\",\n",
            "  \"system_fingerprint\": \"fp_06737a9306\",\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 30,\n",
            "    \"prompt_tokens\": 71,\n",
            "    \"total_tokens\": 101,\n",
            "    \"prompt_tokens_details\": {\n",
            "      \"cached_tokens\": 0,\n",
            "      \"audio_tokens\": 0\n",
            "    },\n",
            "    \"completion_tokens_details\": {\n",
            "      \"reasoning_tokens\": 0,\n",
            "      \"audio_tokens\": 0,\n",
            "      \"accepted_prediction_tokens\": 0,\n",
            "      \"rejected_prediction_tokens\": 0\n",
            "    }\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"こんにちは！私はジョンと言います！\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"こんにちは、ジョンさん！お会いできてうれしいです。今日はどんなことをお話ししたいですか？\"},\n",
        "        {\"role\": \"user\", \"content\": \"私の名前が分かりますか？\"},\n",
        "    ],\n",
        ")\n",
        "print(response.to_json(indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzHmpMiXyDJj"
      },
      "source": [
        "### ストリーミングで応答を得る\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qXm1DALiyDJk",
        "outputId": "8026ba5a-3158-40c5-c5d0-8431f25e3fe7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "こんにちは、ジョンさん！お会いできて嬉しいです。今日はどんなことをお話ししましょうか？"
          ]
        }
      ],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"こんにちは！私はジョンと言います！\"},\n",
        "    ],\n",
        "    stream=True,\n",
        ")\n",
        "\n",
        "for chunk in response:\n",
        "    content = chunk.choices[0].delta.content\n",
        "    if content is not None:\n",
        "        print(content, end=\"\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7jNWsW2yDJk"
      },
      "source": [
        "### JSON モード\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ob_f5M5QyDJk",
        "outputId": "af535643-d3c7-4b51-8ab9-95ef55ac9b04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"people\": [\"おじいさん\", \"おばあさん\"]}\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": '人物一覧を次のJSON形式で出力してください。\\n{\"people\": [\"aaa\", \"bbb\"]}',\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"昔々あるところにおじいさんとおばあさんがいました\",\n",
        "        },\n",
        "    ],\n",
        "    response_format={\"type\": \"json_object\"},\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0E1awVwyDJk"
      },
      "source": [
        "### Vision（画像入力）\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ngsDrJzJyDJk",
        "outputId": "b4448c3e-54fb-413d-cc16-1f4480a3eaa1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "この画像は、書籍の表紙を示しています。タイトルは「ChatGPT/LangChainによるチャットシステム構築【実践】入門」と記載されています。著者の名前が2人分書かれており、その下には「ChatGPT」という文字が大きく表示されています。また、表紙にはカラフルな鳥のイラストが描かれています。全体的に青い背景が使われております。\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "image_url = \"https://raw.githubusercontent.com/yoshidashingo/langchain-book/main/assets/cover.jpg\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"text\", \"text\": \"画像を説明してください。\"},\n",
        "                {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}},\n",
        "            ],\n",
        "        }\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UixLI5HfyDJk"
      },
      "source": [
        "### （コラム）Completions API\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "YN5tUbp_yDJk",
        "outputId": "80eda9f0-ddde-452a-d5b5-e76fb7a2fa0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"cmpl-B9n6euZ5hXBE0BVyxGnp4afVpnggz\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"length\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"text\": \"\\n\\n初めまして、ジョンさん！私はAIのチ\"\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1741673416,\n",
            "  \"model\": \"gpt-3.5-turbo-instruct:20230824-v2\",\n",
            "  \"object\": \"text_completion\",\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 16,\n",
            "    \"prompt_tokens\": 11,\n",
            "    \"total_tokens\": 27\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.completions.create(\n",
        "    model=\"gpt-3.5-turbo-instruct\",\n",
        "    prompt=\"こんにちは！私はジョンと言います！\",\n",
        ")\n",
        "print(response.to_json(indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkgZHh71yDJk"
      },
      "source": [
        "## 2.6. Function calling\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXChSPuSyDJk"
      },
      "source": [
        "### Function calling のサンプルコード\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Qr8ZEHFmyDJk"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "\n",
        "def get_current_weather(location, unit=\"fahrenheit\"):\n",
        "    if \"tokyo\" in location.lower():\n",
        "        return json.dumps({\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": unit})\n",
        "    elif \"san francisco\" in location.lower():\n",
        "        return json.dumps(\n",
        "            {\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": unit}\n",
        "        )\n",
        "    elif \"paris\" in location.lower():\n",
        "        return json.dumps({\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": unit})\n",
        "    else:\n",
        "        return json.dumps({\"location\": location, \"temperature\": \"unknown\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "v5YtobfXyDJk"
      },
      "outputs": [],
      "source": [
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_current_weather\",\n",
        "            \"description\": \"Get the current weather in a given location\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"location\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
        "                    },\n",
        "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
        "                },\n",
        "                \"required\": [\"location\"],\n",
        "            },\n",
        "        },\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "8H6uSZfAyDJk",
        "outputId": "b30ffbcd-b303-4ad1-abb1-593369ba36d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-B9nVUEuNTWQyEP2jfOO2Lcpi5S3bd\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"tool_calls\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"message\": {\n",
            "        \"content\": null,\n",
            "        \"refusal\": null,\n",
            "        \"role\": \"assistant\",\n",
            "        \"tool_calls\": [\n",
            "          {\n",
            "            \"id\": \"call_nUzV2mpYWMYOhDzWvA4TSuBP\",\n",
            "            \"function\": {\n",
            "              \"arguments\": \"{\\\"location\\\":\\\"Tokyo, JP\\\",\\\"unit\\\":\\\"celsius\\\"}\",\n",
            "              \"name\": \"get_current_weather\"\n",
            "            },\n",
            "            \"type\": \"function\"\n",
            "          }\n",
            "        ]\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1741674956,\n",
            "  \"model\": \"gpt-4o-2024-08-06\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"service_tier\": \"default\",\n",
            "  \"system_fingerprint\": \"fp_f9f4fb6dbf\",\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 23,\n",
            "    \"prompt_tokens\": 81,\n",
            "    \"total_tokens\": 104,\n",
            "    \"prompt_tokens_details\": {\n",
            "      \"cached_tokens\": 0,\n",
            "      \"audio_tokens\": 0\n",
            "    },\n",
            "    \"completion_tokens_details\": {\n",
            "      \"reasoning_tokens\": 0,\n",
            "      \"audio_tokens\": 0,\n",
            "      \"accepted_prediction_tokens\": 0,\n",
            "      \"rejected_prediction_tokens\": 0\n",
            "    }\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"東京の天気はどうですか？\"},\n",
        "]\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=messages,\n",
        "    tools=tools,\n",
        ")\n",
        "print(response.to_json(indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "vu6JLoIoyDJk"
      },
      "outputs": [],
      "source": [
        "response_message = response.choices[0].message\n",
        "messages.append(response_message.to_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "SgH-vZQuyDJk",
        "outputId": "d565086a-0aef-457b-e1db-2406518c4965",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": \"celsius\"}\n"
          ]
        }
      ],
      "source": [
        "available_functions = {\n",
        "    \"get_current_weather\": get_current_weather,\n",
        "}\n",
        "\n",
        "# 使いたい関数は複数あるかもしれないのでループ\n",
        "for tool_call in response_message.tool_calls:\n",
        "    # 関数を実行\n",
        "    function_name = tool_call.function.name\n",
        "    function_to_call = available_functions[function_name]\n",
        "    function_args = json.loads(tool_call.function.arguments)\n",
        "    function_response = function_to_call(\n",
        "        location=function_args.get(\"location\"),\n",
        "        unit=function_args.get(\"unit\"),\n",
        "    )\n",
        "    print(function_response)\n",
        "\n",
        "    # 関数の実行結果を会話履歴としてmessagesに追加\n",
        "    messages.append(\n",
        "        {\n",
        "            \"tool_call_id\": tool_call.id,\n",
        "            \"role\": \"tool\",\n",
        "            \"name\": function_name,\n",
        "            \"content\": function_response,\n",
        "        }\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "tmC0k0JXyDJl",
        "outputId": "86a889e8-89ed-47a0-a3f6-c390ab78ff35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "  {\n",
            "    \"role\": \"user\",\n",
            "    \"content\": \"東京の天気はどうですか？\"\n",
            "  },\n",
            "  {\n",
            "    \"content\": null,\n",
            "    \"refusal\": null,\n",
            "    \"role\": \"assistant\",\n",
            "    \"tool_calls\": [\n",
            "      {\n",
            "        \"id\": \"call_nUzV2mpYWMYOhDzWvA4TSuBP\",\n",
            "        \"function\": {\n",
            "          \"arguments\": \"{\\\"location\\\":\\\"Tokyo, JP\\\",\\\"unit\\\":\\\"celsius\\\"}\",\n",
            "          \"name\": \"get_current_weather\"\n",
            "        },\n",
            "        \"type\": \"function\"\n",
            "      }\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"tool_call_id\": \"call_nUzV2mpYWMYOhDzWvA4TSuBP\",\n",
            "    \"role\": \"tool\",\n",
            "    \"name\": \"get_current_weather\",\n",
            "    \"content\": \"{\\\"location\\\": \\\"Tokyo\\\", \\\"temperature\\\": \\\"10\\\", \\\"unit\\\": \\\"celsius\\\"}\"\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "print(json.dumps(messages, ensure_ascii=False, indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "LPlMWKZIyDJl",
        "outputId": "3848aace-7587-4cb8-f7c3-02959c62e377",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-B9na0Z6qRoyyoydXAQUSoBPZMDQRQ\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"message\": {\n",
            "        \"content\": \"現在の東京の天気は気温10℃です。\",\n",
            "        \"refusal\": null,\n",
            "        \"role\": \"assistant\"\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1741675236,\n",
            "  \"model\": \"gpt-4o-2024-08-06\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"service_tier\": \"default\",\n",
            "  \"system_fingerprint\": \"fp_0d4eb8a50b\",\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 14,\n",
            "    \"prompt_tokens\": 66,\n",
            "    \"total_tokens\": 80,\n",
            "    \"prompt_tokens_details\": {\n",
            "      \"cached_tokens\": 0,\n",
            "      \"audio_tokens\": 0\n",
            "    },\n",
            "    \"completion_tokens_details\": {\n",
            "      \"reasoning_tokens\": 0,\n",
            "      \"audio_tokens\": 0,\n",
            "      \"accepted_prediction_tokens\": 0,\n",
            "      \"rejected_prediction_tokens\": 0\n",
            "    }\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "second_response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=messages,\n",
        ")\n",
        "print(second_response.to_json(indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvDEVtYiyDJl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## tool_choice\n",
        "\n",
        "> パラメータ「tool_choice」 Function callingに関連して、Chat Completions APIのリクエストには「tool_choice」というパラメータもあります。tool_choiceというパラメータに\"none\"を指定すると、LLMは関数を呼び出すような応答をせず、通常のテキストを返してきます。tool_choiceを\"auto\"に設定すると、LLMは入力に応じて、指定した関数を使うべきと判断した場合は関数名と引数を返すようになります。パラメータ「tool_choice」のデフォルトの動作は、toolsを与えなかった場合は\"none\"、toolsを与えた場合は\"auto\"となっています。 また、パラメータ「tool_choice」には「{\"type\": \"function\", \"function\": {\"name\": \"<関数名>\"}}」という値を指定することができます。このように関数名を指定すると、LLMに指定した関数を呼び出すことを強制させることができます。\n",
        "\n",
        "\n",
        "西見 公宏; 吉田 真吾; 大嶋 勇樹. LangChainとLangGraphによるRAG・AIエージェント［実践］入門 エンジニア選書 (p. 110). (Function). Kindle Edition."
      ],
      "metadata": {
        "id": "tRr5cGzV8Z_H"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}